{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import papermill as pm\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tempfile\n",
    "import nbformat\n",
    "import stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el directorio base y temporal\n",
    "try:\n",
    "    BASE_DIR = os.path.abspath(os.path.dirname(__file__))\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "TEMP_DIR = os.path.join(BASE_DIR, 'temp')\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "os.chmod(TEMP_DIR, 0o777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para ejecutar notebooks\n",
    "def ejecutar_notebook(notebook_path, parameters=None):\n",
    "    if parameters is None:\n",
    "        parameters = {}\n",
    "    tmp_output_path = os.path.join(TEMP_DIR, 'output_notebook.ipynb')\n",
    "    pm.execute_notebook(\n",
    "        notebook_path,\n",
    "        tmp_output_path,  # Usar un archivo temporal para el output\n",
    "        parameters=parameters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_NOTEBOOK_PATH = os.path.join(BASE_DIR, \"01_LecturayAnalisis.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrador\\Documents\\Python Scripts\\Tesis\\tesisaustral\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Executing: 100%|██████████| 14/14 [00:51<00:00,  3.69s/cell]\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el notebook común\n",
    "ejecutar_notebook(COMMON_NOTEBOOK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variantes de normalización\n",
    "variantes = ['No_Norm', 'MinMax', 'Std', 'Maxabs', 'Robust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 4/4 [00:09<00:00,  2.49s/cell]\n",
      "Executing: 100%|██████████| 5/5 [00:10<00:00,  2.11s/cell]\n",
      "Executing: 100%|██████████| 5/5 [00:13<00:00,  2.80s/cell]\n",
      "Executing: 100%|██████████| 5/5 [00:27<00:00,  5.50s/cell]\n",
      "Executing: 100%|██████████| 5/5 [00:21<00:00,  4.38s/cell]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecución de notebooks de normalización completada.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar notebooks específicos para cada variante del experimento\n",
    "for variante in variantes:\n",
    "    notebook_path = os.path.join(BASE_DIR, f\"02_Norm_{variante}.ipynb\")\n",
    "    #output_notebook = os.path.join(OUTPUT_DIR, f\"02_Norm_{variante}_{datetime.now().strftime('%Y%m%d')}.ipynb\")\n",
    "    ejecutar_notebook(notebook_path, parameters={})\n",
    "    \n",
    "print(\"Ejecución de notebooks de normalización completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:   0%|          | 0/9 [00:00<?, ?cell/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 9/9 [00:30<00:00,  3.40s/cell]\n",
      "Executing: 100%|██████████| 9/9 [00:29<00:00,  3.24s/cell]\n",
      "Executing: 100%|██████████| 9/9 [00:27<00:00,  3.06s/cell]\n",
      "Executing: 100%|██████████| 9/9 [00:24<00:00,  2.75s/cell]\n",
      "Executing: 100%|██████████| 9/9 [00:25<00:00,  2.88s/cell]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecución de notebooks de normalización completada.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for variante in variantes:\n",
    "    notebook_path = os.path.join(BASE_DIR, f\"03_Train_Test.ipynb\")  # Usar el nombre original del notebook\n",
    "    parameters = {\n",
    "        'variante': variante,\n",
    "        'test_size': 0.2,\n",
    "        'random_state': 42  \n",
    "    }\n",
    "    ejecutar_notebook(notebook_path, parameters)\n",
    "\n",
    "print(\"Ejecución de notebooks de normalización completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parámetros TPOT\n",
    "tpot_config = {\n",
    "    \"generations\": 5,\n",
    "    \"population_size\": 20,\n",
    "    \"verbosity\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario de configuración\n",
    "config = {\n",
    "    \"data_paths\": {\n",
    "        # Asegúrate de que cada variante tenga sus correspondientes rutas definidas\n",
    "        \"X_train_No_Norm\": \"X_train_No_Norm.parquet\",\n",
    "        \"X_test_No_Norm\": \"X_test_No_Norm.parquet\",\n",
    "        \"y_train_No_Norm\": \"y_train_No_Norm.parquet\",\n",
    "        \"y_test_No_Norm\": \"y_test_No_Norm.parquet\",\n",
    "        \"X_train_MinMax\": \"X_train_MinMax.parquet\",\n",
    "        \"X_test_MinMax\": \"X_test_MinMax.parquet\",\n",
    "        \"y_train_MinMax\": \"y_train_MinMax.parquet\",\n",
    "        \"y_test_MinMax\": \"y_test_MinMax.parquet\",\n",
    "        \"X_train_Std\": \"X_train_Std.parquet\",\n",
    "        \"X_test_Std\": \"X_test_Std.parquet\",\n",
    "        \"y_train_Std\": \"y_train_Std.parquet\",\n",
    "        \"y_test_Std\": \"y_test_Std.parquet\",\n",
    "        \"X_train_Maxabs\": \"X_train_Maxabs.parquet\",\n",
    "        \"X_test_Maxabs\": \"X_test_Maxabs.parquet\",\n",
    "        \"y_train_Maxabs\": \"y_train_Maxabs.parquet\",\n",
    "        \"y_test_Maxabs\": \"y_test_Maxabs.parquet\",\n",
    "        \"X_train_Robust\": \"X_train_Robust.parquet\",\n",
    "        \"X_test_Robust\": \"X_test_Robust.parquet\",\n",
    "        \"y_train_Robust\": \"y_train_Robust.parquet\",\n",
    "        \"y_test_Robust\": \"y_test_Robust.parquet\"\n",
    "    },\n",
    "    \"tpot_config\": tpot_config\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(BASE_DIR, 'control_config.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el script de modelos\n",
    "subprocess.run(['python', os.path.join(BASE_DIR, '04_Auto_Models.py')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesisaustral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
